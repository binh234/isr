{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/binh234/isr/blob/main/notebooks/Super_Resolution.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyRE9kmrs1ot",
        "outputId": "73d8f063-4080-4b37-cd7d-b78fbfc8b3ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'isr'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 51 (delta 10), reused 47 (delta 10), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (51/51), 3.27 MiB | 3.22 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/binh234/isr.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODrgJnd9tAL6"
      },
      "outputs": [],
      "source": [
        "%cd isr\n",
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "CiQu7AwVtGW5"
      },
      "source": [
        "# Gradio App"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grBrjCAHtHiB"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import gradio as gr\n",
        "from utils import get_upsampler, get_face_enhancer\n",
        "\n",
        "\n",
        "def inference(img, task, model_name, scale):\n",
        "    if scale > 4:\n",
        "        scale = 4  # avoid too large scale value\n",
        "    try:\n",
        "        img = cv2.imread(img, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "        h, w = img.shape[0:2]\n",
        "        if h > 3500 or w > 3500:\n",
        "            raise gr.Error(f\"image too large: {w} * {h}\")\n",
        "\n",
        "        if (h < 300 and w < 300) and model_name != \"srcnn\":\n",
        "            img = cv2.resize(img, (w * 2, h * 2), interpolation=cv2.INTER_LANCZOS4)\n",
        "            return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        if task == \"face\":\n",
        "            upsample_model_name = \"realesr-general-x4v3\"\n",
        "        else:\n",
        "            upsample_model_name = model_name\n",
        "        upsampler = get_upsampler(upsample_model_name)\n",
        "\n",
        "        if task == \"face\":\n",
        "            face_enhancer = get_face_enhancer(model_name, scale, upsampler)\n",
        "        else:\n",
        "            face_enhancer = None\n",
        "\n",
        "        try:\n",
        "            if face_enhancer is not None:\n",
        "                _, _, output = face_enhancer.enhance(\n",
        "                    img, has_aligned=False, only_center_face=False, paste_back=True\n",
        "                )\n",
        "            else:\n",
        "                output, _ = upsampler.enhance(img, outscale=scale)\n",
        "        except RuntimeError as error:\n",
        "            raise gr.Error(error)\n",
        "\n",
        "        output = cv2.cvtColor(output, cv2.COLOR_BGR2RGB)\n",
        "        return output\n",
        "    except Exception as error:\n",
        "        raise gr.Error(f\"global exception: {error}\")\n",
        "\n",
        "\n",
        "def on_task_change(task):\n",
        "    if task == \"general\":\n",
        "        return gr.Dropdown.update(\n",
        "            choices=[\n",
        "                \"srcnn\",\n",
        "                \"RealESRGAN_x2plus\",\n",
        "                \"RealESRGAN_x4plus\",\n",
        "                \"RealESRNet_x4plus\",\n",
        "                \"realesr-general-x4v3\",\n",
        "            ],\n",
        "            value=\"realesr-general-x4v3\",\n",
        "        )\n",
        "    elif task == \"face\":\n",
        "        return gr.Dropdown.update(\n",
        "            choices=[\"GFPGANv1.3\", \"GFPGANv1.4\", \"RestoreFormer\"], value=\"GFPGANv1.4\"\n",
        "        )\n",
        "    elif task == \"anime\":\n",
        "        return gr.Dropdown.update(\n",
        "            choices=[\"srcnn\", \"RealESRGAN_x4plus_anime_6B\", \"realesr-animevideov3\"],\n",
        "            value=\"RealESRGAN_x4plus_anime_6B\",\n",
        "        )\n",
        "\n",
        "\n",
        "title = \"ISR: General Image Super Resolution\"\n",
        "\n",
        "with gr.Blocks(css=\"style.css\", title=title) as demo:\n",
        "    with gr.Row(elem_classes=[\"container\"]):\n",
        "        with gr.Column(scale=2):\n",
        "            input_image = gr.Image(type=\"filepath\", label=\"Input\")\n",
        "            # with gr.Row():\n",
        "            task = gr.Dropdown(\n",
        "                [\"general\", \"face\", \"anime\"],\n",
        "                type=\"value\",\n",
        "                value=\"general\",\n",
        "                label=\"task\",\n",
        "            )\n",
        "            model_name = gr.Dropdown(\n",
        "                [\n",
        "                    \"srcnn\",\n",
        "                    \"RealESRGAN_x2plus\",\n",
        "                    \"RealESRGAN_x4plus\",\n",
        "                    \"RealESRNet_x4plus\",\n",
        "                    \"realesr-general-x4v3\",\n",
        "                ],\n",
        "                type=\"value\",\n",
        "                value=\"realesr-general-x4v3\",\n",
        "                label=\"model\",\n",
        "            )\n",
        "            scale = gr.Slider(\n",
        "                minimum=1.5,\n",
        "                maximum=4,\n",
        "                value=2,\n",
        "                step=0.5,\n",
        "                label=\"Scale factor\",\n",
        "                info=\"Scaling factor\",\n",
        "            )\n",
        "            run_btn = gr.Button(value=\"Submit\")\n",
        "\n",
        "        with gr.Column(scale=3):\n",
        "            output_image = gr.Image(type=\"numpy\", label=\"Output image\")\n",
        "\n",
        "    with gr.Row(elem_classes=[\"container\"]):\n",
        "        gr.Examples(\n",
        "            [\n",
        "                [\"examples/landscape.jpg\", \"general\", 2],\n",
        "                [\"examples/cat.jpg\", \"general\", 2],\n",
        "                [\"examples/cat2.jpg\", \"face\", 2],\n",
        "                [\"examples/AI-generate.png\", \"face\", 2],\n",
        "                [\"examples/Blake_Lively.png\", \"face\", 2],\n",
        "                [\"examples/old_image.jpg\", \"face\", 2],\n",
        "                [\"examples/naruto.png\", \"anime\", 2],\n",
        "                [\"examples/luffy2.jpg\", \"anime\", 2],\n",
        "            ],\n",
        "            [input_image, task, scale],\n",
        "        )\n",
        "\n",
        "    run_btn.click(inference, [input_image, task, model_name, scale], [output_image])\n",
        "    task.change(on_task_change, [task], [model_name])\n",
        "\n",
        "demo.queue(concurrency_count=4).launch(share=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
